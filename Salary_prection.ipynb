{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MIE1624 - Assignment 2\n",
    "## Bibin K. Sebastian\n",
    "## 1003752691"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages that may need PIP install \n",
    "!pip install missingno \n",
    "!pip install mlxtend \n",
    "!pip install seaborn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import required Libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "#plt.style.use('seaborn-whitegrid')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score ,r2_score,explained_variance_score\n",
    "from sklearn.preprocessing import LabelEncoder \n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import make_scorer, r2_score, mean_squared_error, auc, mean_absolute_error\n",
    "from sklearn.model_selection import GridSearchCV, KFold ,StratifiedKFold\n",
    "\n",
    "import missingno as msno # for visualizing the Nans in dataset\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cur_dir = os.getcwd()\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, StratifiedKFold, learning_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble.forest import RandomForestRegressor\n",
    "from sklearn.linear_model import Lasso\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read the survey results as a Data Frame\n",
    "df = pd.read_csv('Kaggle_Salary.csv',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Data dictionary should be the first step and my dictionary is as follows . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![DD](dd.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Higher level visualisations to get an overview of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets see a brief outlook of the missing data as heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "msno.matrix(df) # This will create a heatmap similar seaborn heat map . Black values are not NaNs white area is NaN\n",
    "plt.title(\"Missing values in the Data Frame\",fontsize=18)\n",
    "plt.xlabel(\"Features from 0-395\",fontsize=16)\n",
    "plt.ylabel(\"Survey entries from 1 - 15429\",fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** We can see that from about 10000 rows, many rows are sparse towards the right side of the features. However, most of the first 30 columns are filled in which means we need not drop these rows. These rows need to be closely inspected ** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the Multiple Choice Responses\n",
    "MCR_df = pd.read_csv(\"Kaggle_Salary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCR_df.pop('Unnamed: 0'); # Remove the additional index that cropped up while reading the dataframe\n",
    "MCR_df.pop('index');# Remove the extra index column\n",
    "y =MCR_df.pop('Q9'); #get the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all free Form Responses (including the duration/ Time to fill the answers)\n",
    "MCR_df.drop([col for col in MCR_df.columns if col.find(\"TE\")>0 or col.find(\"seconds\")>0],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replces columns format with the actual survey question for visualization purposes\n",
    "MCR_df.columns = [(col.split(\" - \",1)[0] # split the questions text from first row at the '-' and choose the first part\n",
    "                   .split(\" (Select\",1)[0] # some questions have extra sentences starts with 'Select'\n",
    "                   .split(\" (include\",1)[0]# some questions have extra sentences starts with 'Include' and 'Answers'\n",
    "                   .split(\" (Answers\",1)[0]) for col in MCR_df.loc[0].values]\n",
    "\n",
    "# compiles all the unique question columns\n",
    "questions = []\n",
    "[questions.append(item) for item in MCR_df.columns if item not in questions] # remove all the duplicate entries \n",
    "\n",
    "#drops the extra row for the question columns\n",
    "MCR_df.drop(0,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions[:10] # check if the questions were retrieved correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MCR_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to automate the plotting of all the 50 Questions . The function takes start and end index of the questions\n",
    "\n",
    "def data_plot(start_index,end_index):\n",
    "    # loop for plotting the responses from question #1 to question #50\n",
    "    for i,question in zip(range(start_index,end_index,1),questions[start_index : end_index]):\n",
    "        # prepares the data for plotting. melt is used for questions represented with multiple columns\n",
    "        if len(MCR_df[question].shape)==1: \n",
    "            data = MCR_df[question]\n",
    "        else: \n",
    "            data = MCR_df[question].melt()['value']\n",
    "\n",
    "        # plot specifications\n",
    "        plt.figure(figsize=(15,6.5))\n",
    "        (data\n",
    "         .str.wrap(35) # text wrap for long sentences\n",
    "         .value_counts(sort=True)[:15]# counts then sorts unique values and limits the number of y labels to 15 (to fit in the graph)\n",
    "         .plot.bar(fontsize=20) # plotting of the bar chart\n",
    "\n",
    "         # sets the plot title + a short interpretation\n",
    "         .set_title(\"\\n\\nQ\"+str(i)+\" :\"+pd.Series(question).str.wrap(65)[0]+\n",
    "                    '\\n Top answer: \"'+ str(data.value_counts(sort=True).head(1).index[0])+\n",
    "                    '\"\\n with ' + str(data.value_counts(sort=True).head(1)[0]) + \" responses \\n\",\n",
    "                    fontdict={'fontsize':22})\n",
    "        )\n",
    "        plt.ylabel('Count',fontsize=20)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets visualize the 50 Questions to get an overview of the distribution of Q & A \n",
    "data_plot(0,30) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plot(31,50) # remaining plots "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We get a very high level overview from these plots such as**\n",
    "\n",
    "1. This survey is skewed towards male population! we need to work towards gender equality \n",
    "2. USA & INDIA has maximum participants in this survey \n",
    "3. most of the participants are around 25years old\n",
    "4. Almost half of the participants are from Computer Scinence background\n",
    "5. Most Kaggers are either Data Scientist or Student (Aspiring Data Scientists)\n",
    "6. Main industry is Computer Technology\n",
    "7. Coursera was mentioned as the top MOOC platform ( I agree wholeheartedly - Major user of Coursera)\n",
    "8. Python is the Go to language for most of us \n",
    "9. Many ML models are difficult to understand and interpret \n",
    "*\n",
    "\n",
    "\n",
    "Good insights to know and work on !! lets go deeper \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA Cleaning and Subsetting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dropping the description of the columns as it is interfering with the further processes. <br> I have popualated a Data Dictionary as below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(df.index[0]) # drop the first row containing the questions as it was interfering with the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df1.shape # looks right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.pop('Unnamed: 0'); # getting rid of the pesky pseudo index column \"Unnamed: 0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are a number of columns that has other text in it which showed that the respondants typed responses on their own\n",
    "# even though I believe, there is some information in these columns , I doubt it will be useful since it will blow up \n",
    "# the number of features when onehot encoded . So lets get rid of them for now \n",
    "\n",
    "othertext=[]\n",
    "for head in df1.columns:\n",
    "    if 'TEXT' not in head :\n",
    "        continue\n",
    "    else:\n",
    "        othertext.append(head)\n",
    "othertext       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.drop(labels=othertext, axis =1)\n",
    "df2.pop('Q32_OTHER');\n",
    "# saving the data frame to another data frame df2 after dropping the colums\n",
    "# that contain other text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.pop('index'); # removing the index column "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.rename(columns={'Time from Start to Finish (seconds)':'Time'},inplace=True) # renaming time from start to finish to TIme "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the slightly cleaned dataframe to a csv so that when we read it again, the data types will be read in properly . earlier ,due to the second row of questions, pd read csv function could not interpret all the data types properly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv('Initial_cleaned.csv')  # Write to csv so that we can read properly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3 = pd.read_csv('Initial_cleaned.csv',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.pop('Unnamed: 0'); # getting rid of the pesky pseudo index column \"Unnamed: 0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes.value_counts() # earlier since all the columns had a question row, pandas could not infer the data types properly  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3.dtypes.value_counts() # this looks much more reasonable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking the float columns\n",
    "float_col = []\n",
    "for i,col in enumerate(df3.columns):\n",
    "    if df3[col].dtype == 'float64':\n",
    "        float_col.append(i)\n",
    "df3.iloc[:,float_col].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at higer level outliers\n",
    "df3[(df3['Q9']==500000) & (df3.Q7 == 'I am a student')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[(df3['Q9']==500000) & (df3.Q7 == 'I am a student')].shape # These rows are clear corrupt data. None is 21 years old \n",
    "# and has 30+ years experience and earns 500k USD !!  I wish I could do that :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.drop(df3[(df3['Q9']==500000) & (df3.Q7 == 'I am a student')].index) # dropping the 6 rows straight away - \n",
    "#explanation given above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.dtypes.value_counts() # most of the columns are object type "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.loc[:,df3.dtypes.values == \"int64\"].head() # only time and Q9 is shown as integer I think we have more "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3.loc[:,df3.dtypes.values == \"float64\"].head() #  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding a good subset to conduct regression and predictions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.Q7.value_counts(dropna=False).plot(kind='bar')\n",
    "plt.xlabel(\"Industries\",fontsize = 16)\n",
    "plt.ylabel(\"Count\",fontsize = 16)\n",
    "plt.title(\"Distribution of Job Industries\",fontsize = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective : Since I am graduating soon, I am quite interested in finding out more about the possible industries that I am aiming to get a job in .  I take this assignment as a good opportunity to do so and I have picked three industries that I am interested in . <br>\n",
    "1.Computers/Technology <br>\n",
    "2.Academics/Education <br>\n",
    "3.Accounting/Finance<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job = df3[df3.Q7.isin(['Computers/Technology','Academics/Education','Accounting/Finance'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(df3_job.Q7)\n",
    "locs, labels = plt.xticks()\n",
    "plt.setp(labels, rotation=45)\n",
    "plt.title(\"Distribution of Industries in the chosen Data Frame\")\n",
    "plt.ylabel('Count', fontsize = 18)\n",
    "plt.xlabel('Industries', fontsize = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "industry = np.array(df3_job.Q7.value_counts().index)\n",
    "industry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets have a look at the median salaries for these industries \n",
    "Academics Median salary looks to be lower. It may be because of the fact that in some countries like India and China, academicians tend to get lower salary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check this out \n",
    "\n",
    "#https://stackoverflow.com/questions/7526625/matplotlib-global-legend-and-title-aside-subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx,ind in enumerate(industry): \n",
    "    figs={}\n",
    "    axs={}\n",
    "    figs[idx]=plt.figure(figsize=(10,8)) # create a figure object\n",
    "    axs[idx]=figs[idx].add_subplot(211) # Add a subplot\n",
    "    axs[idx] = sns.boxplot(df3_job['Q9'][((df3_job.Q7 == ind) & df3_job.Q9.between(left=10000,right=250000))],palette='Set2')\n",
    "    plt.title(ind)\n",
    "    plt.xlabel(\"Annual Salary\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lets see how the salary distribution of each industries are across top countries \n",
    "for idx1 , ind in enumerate(industry):\n",
    "    fig = plt.figure(figsize=(35,25))\n",
    "    plt.xlabel(ind)\n",
    "    for idx2 , country in enumerate(df3_job.Q3.value_counts(sort=True).index[:3]):\n",
    "        plt.subplot(4,5,idx2+1)\n",
    "        df3_job[((df3_job['Q3'] == country) & (df3_job['Q7'] == ind)) ].Q9.hist(stacked=True)\n",
    "        plt.title(country,fontsize = 20)\n",
    "        plt.ylabel(ind,fontsize = 18)\n",
    "        plt.xlabel(\"Annual Salary\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We could clearly see that United States of America has a much spread out distribution as well as the highest mean salary amoung top 3 countries. The feature \"Which country you are coming from?\" certainly plays a major role in the salary decision. We will check this out during the feature importance step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring each question and cleaning them as needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleaning outliers and data that clearly looks flawed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at very high salary and very low experience to check for anomalies\n",
    "df3_job[((df3_job['Q9']>300000)  & (df3_job.Q8 == '0-1') & (df3_job.Q6 != 'Chief Officer'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_drp = df3_job[((df3_job['Q9']>300000)  & (df3_job.Q8 == '0-1') & (df3_job.Q6 != 'Chief Officer'))].index\n",
    "index_drp # get the index of the above anomalies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# above rows are clear anomalies and we can drop them . This is okay since we have more than enough rows to carry out regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.drop(index_drp,axis=0,inplace=True) # drop the rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.reset_index(drop=True,inplace=True)# reset index to keep the shape and indexing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** After carrying out the data exploration and creating a data dictionary, below are the columns which has mutiple choice answers in each columns rather than spread out like columns like Q11 or Q13 ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_mult = ['Q1','Q2','Q3','Q4','Q5','Q6','Q7','Q8','Q10','Q12_MULTIPLE_CHOICE','Q17','Q18','Q20','Q22','Q23','Q24','Q25','Q26','Q32','Q37','Q39_Part_1','Q39_Part_2','Q40','Q41_Part_1','Q41_Part_2',\n",
    "'Q43','Q48']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** lets see how many Nans are there in each of these columns and figure out how to clean them ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Ques = []\n",
    "nan_cols = []\n",
    "nans = []\n",
    "# this loop will print number of NaNs in each selected columns \n",
    "for col in cols_mult:\n",
    "    print('#########################################')\n",
    "    print('Nulls','in',col,'(',df[col].iloc[0],')''=', df3_job[col].isnull().sum())\n",
    "    if df3_job[col].isnull().sum() >0 :\n",
    "        nan_cols.append(col)\n",
    "        nans.append(df3_job[col].isnull().sum())\n",
    "        Ques.append(df[col].iloc[0])\n",
    "        \n",
    "    print(df3_job[col].value_counts(dropna = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# that was pretty big list , lets summarise them by only looking at the columns with NaNs from the earlier subset\n",
    "pd.DataFrame(list(zip(nan_cols,Ques,nans)),columns= ['Number','Question', 'Number of Nans'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.reset_index(drop=True); # lets reset the index before proceeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list(set(cols_mult) - set(nan_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'Q6', 'Q2', 'Q3', 'Q1', 'Q4', 'Q7' columns do not have any missing values so I ll leave them alone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets look at the salaries . I see quite a number of outliers . let's investigate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q9.quantile(0.01) # looking at the 1 percentile salary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q9.quantile(0.995) # looking at the 99.5 percentile salary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_index=[]\n",
    "for i in range(df3_job.shape[0]):\n",
    "    if ((df3_job.Q9.iloc[i] < df3_job.Q9.quantile(0.01)) | \n",
    "        (df3_job.Q9.iloc[i] > df3_job.Q9.quantile(0.995))):\n",
    "        outlier_index.append(i)\n",
    "#Let"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(outlier_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets have a brief look at the \n",
    "df3_job.iloc[outlier_index,:].Q9.hist(bins =100)\n",
    "plt.xlabel('Annual Salary')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of outlier salaris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lets look at the sum of NaNs across the rows \n",
    "df3_job.iloc[outlier_index,:].isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.iloc[outlier_index,:].isnull().sum(axis=1).sum()/len(outlier_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** There are quite a lot of missing data across the rows for these 122 rows and the salaries are quite extremes which I feel is not correct. This will prevent the model from generalizing. So I decided to drop these rows **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.drop(outlier_index,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5  -  Which best describes your undergraduate major?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Nulls =', df3_job.Q5.isnull().sum())\n",
    "df3_job.Q5.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job[(df3_job.Q5.isnull())].tail() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### looking at the data set it is quite evident that we all the NaNs are with people who do not have any formal education past high school . so we can replace Nans with ' No_undergrad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q5.fillna(value='No_undergrad',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q5.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q8  -  How many years of experience do you have in your position?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df3_job[(df3_job.Q8.isnull())].head(14) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can safely fill the Q8 column for students with 0-1 years of experience . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df3_job.Q8[((df3_job.Q8.isnull()) & (df3_job.Q6 =='Student' ))]= df3_job.Q8[((df3_job.Q8.isnull()) & (df3_job.Q6 =='Student' ))].fillna('0-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job[(df3_job.Q8.isnull())].head(14) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### looking at the age , I have chosen experience as below for each of the rows and imputed them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = ['30 +', '10-15','20-25','1-2','1-2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job['Q8'].loc[(df3_job.Q8.isnull())] = values # imputing Nans with values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job[(df3_job.Q8.isnull())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q10  -  Does your current employer incorporate machine learning ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q10.value_counts(dropna= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The above NaNs are missed out pretty much in random . lets go deeper by looking at these rows where Q10 is NaN and see if how many other columns are left  unfilled by these people \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job[df3_job.Q10.isnull()].isnull().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job[df3_job.Q10.isnull()].isnull().sum(axis=1).sum()/118"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** We can clearly see that these 118 Data enthusiasts were not dedicated enough to fill most of the columns. This data do not represent the entire population and we can safely drop them  ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.drop(df3_job[df3_job.Q10.isnull()].index,inplace=True) # dropping the rows\n",
    "df3_job.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.reset_index(drop=True,inplace=True) # resetting the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q12  What is the primary tool that you use at work ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q12_MULTIPLE_CHOICE.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3_job[df3_job.Q12_MULTIPLE_CHOICE.isnull()].isnull().sum(axis=1).sum()/639 \n",
    "# Check across the rows for the average numbers of Nans (across 359 columns) for the NaNs  in Q12 column. \n",
    "# We can see that there are high number of Nans across these rows .. 318 in 360! \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at the data where Q12 is left unfilled \n",
    "df3_job[df3_job.Q12_MULTIPLE_CHOICE.isnull()].loc[:,:'Q12_MULTIPLE_CHOICE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I tried encoding the Nans with a separate 'UNKNOWN' category . models were performing much worse . \n",
    "# since I had enough data points. I decided to drop these rows\n",
    "df3_job.drop(df3_job[df3_job.Q12_MULTIPLE_CHOICE.isnull()].index,inplace=True)\n",
    "df3_job.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q17 \tWhat specific programming language do you use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q17.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at the data where Q17 is Nan, I could see that most of the Nans has other related columns filled in regarding the programming language of choice etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3_job[df3_job.Q17.isnull()].Q18.value_counts(dropna=False) # Most of the Nans in Q17 has answered Q18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will fill it with a 'None' category which would mean they did not use any of these languages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q17.fillna(value='None',inplace=True)\n",
    "df3_job.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q18 \tWhat programming language would you recommend?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q18.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# very few Nans in this column and it makes sense to fill the Nans with Mode of the column which is python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q18.fillna(df3_job.Q18.mode()[0],inplace=True) # using mode as the fillna value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q20 \tOf the choices that you selected in the previous section ..?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3_job.Q20.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1882 Nans here . it is makes sense to group these Nans seprately "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q20.fillna(value='None',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q22    --- which specific library was used the most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q22.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q22.fillna(value='None',inplace=True) # Similar to above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q23 Approximately what percent of your time at work do you spend coding ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q23.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job[df3_job.Q23.isnull()].isnull().sum(axis=1)\n",
    "# most of the Nan rows have sparce entries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping these 122 rows \n",
    "df3_job.drop(df3_job[df3_job.Q23.isnull()].index,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets look at India especially about coders with more than Three hundred thousand USD annual salary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job[(df3_job['Q9'] > 300000) & (df3_job.Q3 == 'India')].loc[:,'Q9'] # look at these salaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I see that these annual salaries in USD is not achievable for a business analyst having 2 years experience and aged \n",
    "#25, in India . So it is safe to assume that they used their Indian salary instead of US Salary . I am quite certain since I have \n",
    "# been working in India . I wll scale it by dividing with 70 ( 1 USD = 70 INR)\n",
    "val_impute = df3_job[(df3_job['Q9'] > 300000) & (df3_job.Q3 == 'India')].loc[:,'Q9'].values/70\n",
    "val_impute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.loc[df3_job[(df3_job['Q9'] > 300000) & (df3_job.Q3 == 'India')].index,'Q9'] = val_impute # correcting the salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After looking at the data frame, I can see that 95% of these Nans are 20-25 years of age and I expect we can fill the\n",
    "#Q23 nans with median \n",
    "#df3_job.Q23.fillna(value='50% to 74% of my time' ,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working on ordinal columns -- Q23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df3_job.Q23.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3_job_ = df3_job.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3_job = df3_job_.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** since the above feature is ordinal I would like to keep the order and label encode this column *** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = {'50% to 74% of my time':3 ,'25% to 49% of my time' : 2, '1% to 25% of my time' : 1, '100% of my time':5 ,'0% of my time':0,'75% to 99% of my time':4 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q23 = df3_job.Q23.map(mapper) # label encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q23.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job[df3_job.Q23.isnull()].Q3.value_counts() # sanity check "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q24  -  Approximately what percent of your time at work or school is spent actively coding?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3_job.Q24.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q24.fillna(value='Other',inplace=True) # fill Nans as  'Other' since I could not find any stron reason to do anythin else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q25  -  For how many years have you used machine learning methods (at work or in school)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df3_job.Q25.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q25.fillna(value='Other',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df3_job.Q26.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df3_job[df3_job.Q24.isnull()][df3_job.Q25.isnull()][['Q23','Q24','Q25','Q26']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df3_job= df3_job.drop(df3_job[df3_job.Q25.isnull()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3_job[df3_job.Q24.isnull()][df3_job.Q25.isnull()][['Q23','Q24','Q25','Q26']].fillna('other',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df3_job.Q24.fillna(value='1-2 years',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = {'I have never written code but I want to learn':2,'< 1 year':1,'1-2 years':3,'3-5 years':4,'5-10 years':5,'10-20 years':6,\\\n",
    "         'I have never written code and I do not want to learn':1,'20-30 years':7,'30-40 years':8,'40+ years':9,'Other':0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q24.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q24= df3_job.Q24.map(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q24.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q24.hist() # good normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q25.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3_job.Q25.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = {'< 1 year':2,'1-2 years':3,'2-3 years':4,'3-4 years':5,'4-5 years':6,\\\n",
    "         'I have never studied machine learning and I do not plan to':0,'5-10 years':7,'10-15 years':8,'20+ years':9,\\\n",
    "          'I have never studied machine learning but plan to learn in the future':2,'Other':1} \n",
    "# used ordinal values in the asending order of experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q25= df3_job.Q25.map(mapper) # Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q25.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3_job.Q26.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q26.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job[df3_job.Q26.isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at the data. These 28 people are more likely to be a may be case\n",
    "df3_job.Q26.fillna(value='Maybe',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper = {'Definitely yes':6,'Probably yes':5,'Maybe':4,'Other':3,'Probably not':2,\\\n",
    "         'Definitely not':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q26= df3_job.Q26.map(mapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q26.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q26.astype('int');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3_job.Q26= df3_job.Q26.astype('category',);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df3_job.Q26.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection  and Feature Importance visualisations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Why is Feature Selection important ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature selection is very important in machine learning  because it serves as a fundamental technique to pick the most efficient variables that can be used to predtict the target. Adding to that is the reduction  of the curse of dimensionality or help deal with overfitting. This will eventually help in a lean and efficient model that can be deployed in production efficiently. Further, accurate feature set corresponds to the best bias-variance tradeoff point for the learning algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will start off with a selected set of features that I had cleaned earlier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= df3_job[['Q1','Q2','Q3','Q4','Q5','Q6','Q7','Q8','Q9','Q10','Q12_MULTIPLE_CHOICE','Q17','Q20','Q22','Q18','Q23','Q24','Q25','Q26']]\n",
    "dataset.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.to_csv(\"dataset.csv\") # to be used in Neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = dataset.pop('Q9'); # separate the target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### defining a function to find the unbiased fit estimator Adjusted $R^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjusted_r2(y_true,y_pred,data):\n",
    "    r2 = r2_score(y_true,y_pred)\n",
    "    return(1 - (1-r2)*(data.shape[0]-1)/(data.shape[0]-data.shape[1]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the features to categorical \n",
    "dataset.Q23 = dataset.Q23.astype('category')\n",
    "dataset.Q24 = dataset.Q23.astype('category')\n",
    "dataset.Q25 = dataset.Q25.astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** One hot encoding to ensure that the columns with multiple categories are separated in different columns. I am using pandas get_dummies function to encode the dataframe (will encode only object or categorical type columns). While doing so , to ensure that we get rid of the dummy variable trap, drop_first parameter needs to be set as True.This step will produce k-l features from a column with k categories . ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.get_dummies(dataset,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape # looks like get_dummies did its work!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.head() # nice and easy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** we have 213 features now . lets see how many is can be removed. I would like to check Lasso,RFE and Random Forest regressor  *** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test spliting with test set of 20%\n",
    "X_train, X_test, y_train , y_test = train_test_split(dataset.values,y, test_size=0.2, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for Lasso it would help to scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = x_scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = x_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "las = Lasso() # using Lasso regularisation to order the features in the order of importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "las.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = las.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_r2(y_train,pred,X_train) # using adjsted R2 score to get an idea of the fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "las_importances = las.coef_  # For lasso regression coefficients indicate the importance of the features\n",
    "las_importances.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "indices = np.argsort(abs(las_importances))[::-1] # arg sort will deliver the indices .. absolute value is important \n",
    "# as some coeffients may negatively effect the target variable\n",
    "indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_lasso =[(dataset.columns[i]) for i in indices ] # get the important features in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importancies of LASSO Regression \n",
    "num_to_plot = 15\n",
    "feature_indices = indices\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "  \n",
    "for f in range(num_to_plot):\n",
    "    print(\"%d. %s %f \" % (f + 1, \n",
    "            dataset.columns[indices[f]], \n",
    "            las_importances[indices[f]]))\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.title(u\"Feature Importance\")\n",
    "bars = plt.bar(range(num_to_plot), \n",
    "               abs(las_importances[indices[:num_to_plot]]),\n",
    "       color=([str(i/float(num_to_plot+1)) \n",
    "               for i in range(num_to_plot)]),\n",
    "               align=\"center\")\n",
    "ticks = plt.xticks(range(num_to_plot), \n",
    "                   feature_lasso,rotation=90)\n",
    "plt.xlim([-1, num_to_plot])\n",
    "plt.legend(bars, [u''.join(dataset.columns[indices[i]]) \n",
    "                  for i in range(num_to_plot)]);\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Coeffients')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## explanations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### using Random forest we can check out feature importance . This  method is based on the Information gain while splitting on important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = forest.feature_importances_\n",
    "\n",
    "indices = np.argsort(importances)[::-1] # sort the features and get index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.columns[indices[0:20]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the feature importancies of the forest\n",
    "num_to_plot = 15\n",
    "feature_indices = indices\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "  \n",
    "for f in range(num_to_plot):\n",
    "    print(\"%d. %s %f \" % (f + 1, \n",
    "            dataset.columns[indices[f]], \n",
    "            importances[indices[f]]))\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.title(u\"Feature Importance\")\n",
    "bars = plt.bar(range(num_to_plot), \n",
    "               importances[indices[:num_to_plot]],\n",
    "       color=([str(i/float(num_to_plot+1)) \n",
    "               for i in range(num_to_plot)]),\n",
    "               align=\"center\")\n",
    "ticks = plt.xticks(range(num_to_plot), \n",
    "                   dataset.columns[indices[0:num_to_plot]],rotation=90)\n",
    "plt.xlim([-1, num_to_plot])\n",
    "plt.legend(bars, [u''.join(dataset.columns[indices[i]]) \n",
    "                  for i in range(num_to_plot)]);\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion on Feature Importance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Looking at the feature importances from both Lasso and Random forest regression . we can see that the country where data enthusiast is from, takes up a very high position in the top feature. This correlation is visible from the correlation plot as well. USA dominates both the feature importance results  along with 'We have well established ML methods (i.e., models in production for more than 2 years)' .These makes intuitive sense and we can see that most of the important features are more or less the same ** <br>\n",
    "Important original attributes are .\n",
    "1. Country \n",
    "2. Age \n",
    "3. Use of well established ML models in the company (Q10)\n",
    "4. Industry of work\n",
    "5. Use of Visualisations like Matplotlib and Seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using  Sequential feature selection from MLXTEND package to sequentially select the features that matters. \n",
    "This method is compute expensive <br> reference \n",
    "https://pypi.org/project/mlxtend/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression() \n",
    "# Sequential feature selection function needs a regressor to check the features sequentially I use the Linear Regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = lin_reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_r2(y_train,pred,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_reg = LinearRegression() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Install mlxtend\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "selector = SequentialFeatureSelector(lin_reg, verbose=3, k_features='best', n_jobs=-1,cv=5,scoring = 'r2')\n",
    "\n",
    "# k_features='best' find the best features from the whole set \n",
    "\n",
    "#selector.fit(X_train, y_train)\n",
    "#Takes almost an hour run time on a google cloud vm with 8 Cores and 30 GB ram !!  So I saved the features as a \n",
    "# a data frme and attached with the submission.\n",
    "# please feel free to uncomment and try it yourself "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#pd.DataFrame(selector.subsets_).to_csv('SFS_subset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq_feat_imp = [(dataset.columns[i],i ) for i in selector.k_feature_idx_]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(seq_feat_imp).to_csv(\"SFS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SFS_selection = pd.read_csv(\"SFS.csv\",header=None,names=['index','SFS_Sel_Features','SFS_Sel_index'])\n",
    "SFS_selection.drop(index=0,axis=0,inplace=True)\n",
    "\n",
    "# read the CSV that contains the selected features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "las.fit(X_train_scaled[:,SFS_selection.SFS_Sel_index],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = las.predict(X_train_scaled[:,SFS_selection.SFS_Sel_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjusted_r2(y_train,pred,X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sel = X_train[:,SFS_selection.SFS_Sel_index]\n",
    "X_test_sel = X_test[:,SFS_selection.SFS_Sel_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sel.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential feature extractor selected 99 feature and they are not hampering the test score . Moving forward I will use thee selected features for model implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lets check the correlation plot of the selected features . Independence of the features is as important assumtion on a linear model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_corr = pd.concat([y,dataset],axis=1) # concatenate the dataset frame with salary so that we can check the correlatiojn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that will use the data set and thresold to return column names that has correlation more than the threshold\n",
    "def correlation(dataset,threshold):\n",
    "    col_corr=set() # set will contains unique values.\n",
    "    corr_matrix=dataset.corr() #finding the correlation between columns.\n",
    "    for i in range(len(corr_matrix.columns)): #number of columns\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i,j])>threshold: #checking the correlation between columns.\n",
    "                colName=corr_matrix.columns[i] #getting the column name\n",
    "                col_corr.add(colName) #adding the correlated column name heigher than threshold value.\n",
    "    return col_corr #returning set of column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_cols = correlation(dataset_corr,0.7) # call the function and \n",
    "correlated_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlated_cols = set(correlated_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix=dataset_corr.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corr_matrix['Q9'].abs().sort_values(ascending = False) # checking the columns that are mostly correlated with Salary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "f, ax = plt.subplots(figsize=(20, 15))\n",
    "sns.heatmap(corr_matrix)\n",
    "plt.title(\"Correlation Plot \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets check if the correlated columns are in the selected list of columns by SFS  and only keep one column from that set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(set(SFS_selection.SFS_Sel_Features.values) - correlated_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(SFS_selection.SFS_Sel_Features)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Great .. SFS has already done the good job of removing correlated features and keep only one column from the correlated set . We are in good shape to do model implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Lasso regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = StandardScaler() # Lasso works well with scaled features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sel_scaled = x_scaler.fit_transform(X_train_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sel_scaled = x_scaler.transform(X_test_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_reg = Lasso(random_state=9) # lets try the default lasso parameters we can tune them after getting benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carry out 10 fold cross validation the Ridge regression model\n",
    "scores_lasso = cross_val_score(n_jobs=-1,estimator=lasso_reg, X=X_train_sel_scaled, y=y_train, cv=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lets plot the average R2 score and the variance \n",
    "sns.lineplot(y=scores_lasso*100,x=range(10))\n",
    "plt.xlim(0,10)\n",
    "plt.ylim(0,100)\n",
    "\n",
    "plt.legend(['Average R2 Score'])\n",
    "plt.title(\"Cross validation Score\")\n",
    "plt.xlabel(\"Folds\")\n",
    "plt.ylabel(\"R2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average Accuracy for Gradient Boosting Regressor over 10 folds :\",round(scores_lasso.mean() ,2))\n",
    "print(\"Varience of the Accuray Gradient Boosting Regressor over 10 folds :\",round(scores_lasso.std()*100,2), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_results = {'Lasso': [round(scores_lasso.mean() ,2), round(scores_lasso.std(),2)],\\\n",
    "               'Ridge': [3, 4] ,'GBM': [1, 2], 'KNN_Reg': [3, 4] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(reg_results, index=['Mean','Std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion on Lasso "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*LASSO (Least Absolute Shrinkage Selector Operator) is a regluarlised linear regression and . It fits a linear regressor which as a penalty term that prevents the Beta coefficients from blowing up . Since Lasso uses L1 distance as the measure of estimator for  Beta values across the features, it does a good job in pruning out irrelevant features. Fast implementation along with the ability to prune out features was the main pro of this algorithim and it was one of the main criterion for choosing this model. On the other hand this model is not much of use in non linear data unless we insert engineered polynomial features.\n",
    "\n",
    "While going for the cross validation the model accuracy fluctuates across the folds quite a bit. One reason for the variance is due to the data which has very high variability *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter tuning -Lasso\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "lasso_params = {'alpha':[0.001,0.1,0.5,1,10,20,30,40,50,500 ]}\n",
    "\n",
    "\n",
    "Lasso_grid = GridSearchCV(lasso_reg, param_grid=lasso_params,cv=10, n_jobs=-1, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso_grid.fit(X_train_sel_scaled, y_train)# fit the gridsearch instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lasso_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best R2 score after Grid search \" ,round(Lasso_grid.best_score_,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean Variance after Grid search \" ,round(Lasso_grid.cv_results_['std_test_score'].mean()*100,2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results_l= pd.DataFrame(Lasso_grid.cv_results_)\n",
    "grid_results_l.index=grid_results_l.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_results_l.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = lasso_params['alpha']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.lineplot(data = grid_results_l[['mean_test_score','mean_train_score']],x=alphas,y='mean_test_score')\n",
    "sns.lineplot(data = grid_results_l[['mean_test_score','mean_train_score']],x=alphas,y='mean_train_score')\n",
    "plt.legend(['Test Accuracy','Train Accuracy'])\n",
    "plt.title(\"Bias- Variance Trade off \")\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.ylabel(\"R2_score\")\n",
    "plt.xlim(0,max(alphas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion on Bias variance Trade off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** One of the most important param\n",
    "Regarding the bias variance trade off for Lasso is aplha - since we have done our due diligence by choosing the best features already there is very little that can be done by Gridsearch . I chose to tune the lasso regularisaton coefficient alpha for bias vaiance analysis . for the best test accuracy , alpha was found to be 10 **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model using Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_reg = Ridge(random_state=9) # use default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Carry out 10 fold cross validation the Ridge regression model\n",
    "scores_ridge = cross_val_score(n_jobs=-1,estimator=ridge_reg, X=X_train_sel_scaled, y=y_train, cv=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.lineplot(y=scores_ridge*100,x=range(10))\n",
    "plt.xlim(0,10)\n",
    "plt.ylim(0,100)\n",
    "\n",
    "plt.legend(['Average R2 Score'])\n",
    "plt.title(\"Cross validation Score\")\n",
    "plt.xlabel(\"Folds\")\n",
    "plt.ylabel(\"R2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average Accuracy for Gradient Boosting Regressor over 10 folds :\",round(scores_ridge.mean() ,2))\n",
    "print(\"Varience of the Accuray Gradient Boosting Regressor over 10 folds :\",round(scores_ridge.std()*100,2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion on Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Similar to Lasso  regluarlised linear regression and . It fits a linear regressor which as a penalty term that prevents the Beta coefficients from blowing up . Here the algorithm uses  L2 distance as the measure of estimator for  Beta values across the features. Howver, it will not completely eliminate the feature like Lasso since the distance measure boundary is circular in nature .  \n",
    "\n",
    "Fast implementation along with the ability to keep beta values in check features was the main pro of this algorithim and it was one of the main criterion for choosing this model. simlar to Lasso this model is not much of use in non linear data unless we insert engineered polynomial features.\n",
    "\n",
    "While going for the cross validation the model accuracy fluctuates across the folds quite a bit. One reason for the variance is due to the data which has very high variability.\n",
    "*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyper parameter tuning Ridge "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "ridge_params = {'alpha':[0.1,0.5,0.8,.9,0.99,2,3,4,5,6,20,30,40,50,500]}\n",
    "\n",
    "\n",
    "ridge_grid = GridSearchCV(ridge_reg, param_grid=ridge_params,cv=10, n_jobs=-1, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_grid.fit(X_train_sel_scaled, y_train)# fit the gridsearch instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ridge_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best R2 score after Grid search \" ,round(ridge_grid.best_score_,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"mean Variance after Grid search \" ,round(ridge_grid.cv_results_['std_test_score'].mean()*100,2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results= pd.DataFrame(ridge_grid.cv_results_)\n",
    "grid_results.index=grid_results.param_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plotting Bias Variance Trade off by looking at the ERRORS \n",
    "(1-grid_results[['mean_test_score','mean_train_score']]).plot()\n",
    "plt.legend(['Test Error','Train Error'])\n",
    "plt.title(\"Bias- Variance Trade off \")\n",
    "plt.xlabel(\"Alpha\")\n",
    "plt.ylabel(\"R2_score\")\n",
    "#plt.ylim(0,1.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion on Bias Variance Tradeoff\n",
    "\n",
    "** One of the most important param Regarding the bias variance trade off for Ridge regression is still alpha .howver the algo uses L2 norm - since we have done our due diligence by choosing the best features already there is very little that can be done by Gridsearch . I chose to tune the Ridge regularisaton coefficient alpha for bias vaiance analysis . for the best test accuracy , alpha was found to be 50 **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GradientBoostingRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-566fa32d82dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgbm_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_estimators\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# default gradent boosting parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#(used the n_estimatoros from hyper parameter tuning)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GradientBoostingRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "gbm_reg = GradientBoostingRegressor(random_state=9) # default gradent boosting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gbm_reg.fit(X_train_sel, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scores_gbm = cross_val_score(n_jobs=-1,estimator=gbm_reg, X=X_train_sel, y=y_train, cv=10) # cross validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.lineplot(y=scores_gbm*100,x=range(10),estimator='mean')\n",
    "plt.xlim(0,10)\n",
    "plt.ylim(0,100)\n",
    "\n",
    "plt.legend(['Average R2 Score'])\n",
    "plt.title(\"Cross validation\")\n",
    "plt.xlabel(\"Folds\")\n",
    "plt.ylabel(\"R2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average Accuracy for Gradient Boosting Regressor over 10 folds :\",round(scores_gbm.mean(),2),)\n",
    "print(\"Varience of the Accuray Gradient Boosting Regressor over 10 folds :\",round(scores_gbm.std()*100,2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion on GBM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Gradient boosting algorithm is an ensemble method which uses a number of boosted trees and aggregate them to come to a prediction. Decision trees formed one at a time, where each new tree helps to correct errors made by previously trained tree. Since this algo is based on decision trees, they are inherently better at handling missing values and do not need any scaling. \n",
    "\n",
    "GBDT training generally takes longer because of the fact that trees are built sequentially and chances of over fitting is very high if not kept a check . Boosting and ensemble methods were best performers in Kaggle competitions and they help up erk out maxmimum information from the given data set. This method also performs better even if the data is quite non linear\n",
    "\n",
    "Here we can see that the ensemble method has much less variance compared to previous methods.* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper parameter tuning -GBM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gbm_params = {'n_estimators':range(100,350,20)}  # parameter grid\n",
    "\n",
    "#scoring = {'ERROR': make_scorer(mean_squared_error), 'Accuracy': make_scorer(r2_score)}\n",
    "\n",
    "gbm_grid = GridSearchCV(gbm_reg, param_grid=gbm_params,cv=10, n_jobs=-1, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "gbm_grid.fit(X_train_sel, y_train)# fit the gridsearch instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbm_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best R2 score after Grid search \" ,round(gbm_grid.best_score_,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"mean Variance after Grid search \" ,round(gbm_grid.cv_results_['std_test_score'].mean()*100,2),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results= pd.DataFrame(gbm_grid.cv_results_) # convert to DF\n",
    "grid_results.index=grid_results.param_n_estimators # get the index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plotting Bias Variance Trade off\n",
    "(1-grid_results[['mean_test_score','mean_train_score']]).plot()\n",
    "plt.legend(['Test Error','Train Error'])\n",
    "plt.title(\"Bias- Variance Trade off \")\n",
    "plt.xlabel(\"N_Estimators\")\n",
    "plt.ylabel(\"R2_score\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion on Bias Variance Tradeoff\n",
    "\n",
    "** In GBM I chose to tune the number of estimators (number of trees) that are formed . After exploring the paramter grid, it was found that 300 is the number that optimizes test error as well as the training error. ** \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNNregressoor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_scaler = StandardScaler() # create standard scaler object for knn since it is distance based. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sel_scaled = x_scaler.fit_transform(X_train_sel)  # fit the scaler and transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sel_scaled = x_scaler.transform(X_test_sel) # tranform using the fitted scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_reg = KNeighborsRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scores_knn = cross_val_score(n_jobs=-1,estimator=knn_reg, X=X_train_sel_scaled, y=y_train, cv=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.lineplot(y=scores_knn*100,x=range(10),estimator='mean')\n",
    "plt.xlim(0,10)\n",
    "plt.ylim(0,100)\n",
    "\n",
    "plt.legend(['Average R2 Score'])\n",
    "plt.title(\"Cross validation\")\n",
    "plt.xlabel(\"Folds\")\n",
    "plt.ylabel(\"R2_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average Accuracy for Gradient Boosting Regressor over 10 folds :\",round(scores_knn.mean(),2), )\n",
    "print(\"Varience of the Accuray Gradient Boosting Regressor over 10 folds :\",round(scores_knn.std()*100,2), '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion on KNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNNRegressor is based on the K nearest neighbour princile.It is a non parametric approach.  The target is predicted by local interpolation of the targets associated of the nearest neighbors in the training set.\n",
    "\n",
    "Advantages are easy to code and understand, and scales up to big data.Disadvantages are sensitive to data and tuning.I wanted to try out a different model to our dataset to see if knn based model will do any good . \n",
    "\n",
    "In our case I feel that knn is not a great choice as we can clearly see that the r2 score is way lower that others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyper parameter tuning KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "knn_params = {'n_neighbors':range(5,50,10)}\n",
    "\n",
    "knn_grid = GridSearchCV(knn_reg, param_grid=knn_params,cv=10, n_jobs=-1, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid.fit(X_train_sel_scaled, y_train)# fit the gridsearch instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_results= pd.DataFrame(knn_grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_results.index=grid_results.param_n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plotting Bias Variance Trade off\n",
    "(1-grid_results[['mean_test_score','mean_train_score']]).plot()\n",
    "plt.legend(['Test Error','Train Error'])\n",
    "plt.title(\"Bias- Variance Trade off \")\n",
    "plt.xlabel(\"N_Estimators\")\n",
    "plt.ylabel(\"R2_score\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion on Bias Variance Tradeoff\n",
    "\n",
    "** In Kneighboursregressor I chose to tune the number of nearest neighbors . After exploring the paramter grid, it was found that 30 is the number that optimizes test error as well as the training error . \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# comparision between models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_results = {'Lasso': [round(scores_lasso.mean() ,2), round(scores_lasso.std(),2)],\\\n",
    "               'Ridge': [round(scores_ridge.mean() ,2), round(scores_ridge.std() ,2)] ,\n",
    "               \n",
    "               'GBM': [round(scores_gbm.mean(), 2),round(scores_gbm.std(), 2)], 'KNN_Reg': [round(scores_knn.mean(),2), round(scores_knn.std(),2)] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp = pd.DataFrame(reg_results, index=['Mean','Std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comp.loc['Variance',:]  = comp.loc['Variance',:].apply(np.square). \n",
    "#Did not convert STD to Variance since the data pointes were very small to visulize side by side with accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "comp.plot(kind='bar')\n",
    "plt.xlabel(\"Metrics\")\n",
    "plt.title(\"Comparision between different models - Mean accuracy and Variance\")\n",
    "plt.ylim(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing optimal Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I chose the gradient boosting model as it had the best r2_score and less variance as per the graph shown above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_reg = GradientBoostingRegressor(n_estimators=300,random_state=9) # using the best model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbm_reg.fit(X_train_sel, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tr = gbm_reg.predict(X_train_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ts = gbm_reg.predict(X_test_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Mean Squred error from Train set', 928910250.089)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(mean_squared_error(y_train,pred_tr),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Final Mean Squred error =\",round(mean_squared_error(y_test,pred_ts),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Difference in train and test mean squared error = ' ,1264952288.319 - 917209405.257)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Final Model Coefficient of determination Train Set =\",round(adjusted_r2(y_train,pred_tr,X_train_sel),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Final Model Coefficient of determination Test Set =\",round(adjusted_r2(y_test,pred_ts,X_test_sel),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion on the selected model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Given the inherent issues with the data set and the subset of the problem I was looking at, I feel that explaining more than 60% of the variance is an indication of a good model. Gradient boosting model showed slightly higher R2 score for the test set I feel that since our data has quite a lot outliers , MSE gets biased with these values arne swing to  extremas.So in this assignment I primarily made use of R2 Score . Even R2Score is biased and I had defined a function to compute Adjusted R2 score. Howver, Adjsted R2 score will differ from R2 score based on the number of features and the sample size.Adjusted R2 Score is  a quite useful metric while selecting features.  R2 Score is a measure of the explained variance.In other words, how much variance of the data set is explaned by the model. It takes values from 0 to 1 with 0 being the worst. R2 score will not decrease with the number of predictors added. Adjusted R2 Score fixes this issue by penalizing the addition of a new feature. \n",
    "\n",
    "In our case the slightly higher Test R2 score can be attributed to the difference in distribution of the train and test set and the sparcity and randomness in the the dataset. The model does not look to be overfitting since the test set performed well with model created. I feel that it is slightly underfit or the inherent Bayes error (irremovable error) in the dataset is quite high. The suspicion on the Bayes error is quite valid since almost 6 regressor models and Neural Network model gave similary metric of model fit \n",
    "\n",
    "\n",
    "However, I feel that the model could be improved much more  using below mentiond methods \n",
    "\n",
    "1. Spend more time on adding more relevant features and use feature selection \n",
    "2. Better feature engineering - polynomial features to be introduced \n",
    "3. Better utilisation of other text fields that was dropped to make data set simpler\n",
    "4. Conduct Gridsearch on more parameters for the same regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thank you very much for the support during the course and relevant assignments. Happy holidays !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
